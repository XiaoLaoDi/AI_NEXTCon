{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning Workshop: Beijing - Part I\n",
    "In this course we will run through a series of exercises that will illustrate how to use different variations of active learning. The goal in active learning it to train models that will use less data in a more intelligent way thereby resulting in increased accuracy.\n",
    "\n",
    "To get started make sure to copy the data onto your machine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train classifier\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "EXPERIMENT_RESULTS = None\n",
    "\n",
    "ROOT_DATA = '/Users/kvajapey/Documents/CrowdFlower/Conferences/Beijing/workshop/data/gender_detection/' #!! SET THIS FOLDER!\n",
    "\n",
    "TRAIN_FLAGS = {\n",
    "    'background_frequency':0.1,\n",
    "    'background_volume':0.1,\n",
    "    'batch_size':20,\n",
    "    'check_nans':False,\n",
    "    'clip_duration_ms':10000,\n",
    "    'data_dir':'', #/Users/kvajapey/Documents/CrowdFlower/Conferences/Beijing/workshop/data/gender_detection/training_data/supervised\n",
    "    'data_url':'',\n",
    "    'eval_step_interval':10,\n",
    "    'feature_bin_count':40,\n",
    "    'how_many_training_steps':'1,1',\n",
    "    'learning_rate':'0.001,0.0001',\n",
    "    'model_architecture':'conv',\n",
    "    'preprocess':'mfcc',\n",
    "    'quantize':False,\n",
    "    'sample_rate':48000,\n",
    "    'save_step_interval':10,\n",
    "    'silence_percentage':0,\n",
    "    'start_checkpoint':'',\n",
    "    'summaries_dir':'/tmp/retrain_logs',\n",
    "    'testing_percentage':5,\n",
    "    'time_shift_ms':100.0,\n",
    "    'train_dir':'/tmp/speech_commands_train',\n",
    "    'unknown_percentage':0,\n",
    "    'validation_percentage':5,\n",
    "    'wanted_words':'male,female',\n",
    "    'window_size_ms':30.0,\n",
    "    'window_stride_ms':10.0\n",
    "}\n",
    "\n",
    "FREEZE_FLAGS = {\n",
    "    'clip_duration_ms':10000,\n",
    "    'clip_stride_ms':30,\n",
    "    'feature_bin_count':40,\n",
    "    'model_architecture':'conv',\n",
    "    'output_file':'',       # frozen.pb\n",
    "    'preprocess':'mfcc',\n",
    "    'quantize':False,\n",
    "    'sample_rate':48000,\n",
    "    'start_checkpoint':'',  # /tmp/speech_commands_train/conv.ckpt-2\n",
    "    'wanted_words':'male,female',\n",
    "    'window_size_ms':30.0,\n",
    "    'window_stride_ms':10.0\n",
    "}\n",
    "\n",
    "INFERENCE_FLAGS = {\n",
    "    'wav_dir':'',      # /Users/kvajapey/Documents/CrowdFlower/Conferences/Beijing/workshop/data/gender_detection/female_test\n",
    "    'graph':'',        # /Users/kvajapey/Documents/CrowdFlower/repos/AI_NEXTCon/frozen.pb\n",
    "    'labels':'',       # /tmp/speech_commands_train/conv_labels.txt\n",
    "    'input_name': 'wav_data:0',\n",
    "    'output_name': 'labels_softmax:0',\n",
    "    'how_many_labels': 2\n",
    "}\n",
    "\n",
    "CLASSIFIER_STATS = {\n",
    "    'supervised_learning' : {'x':[], 'y':[]}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_commands import train\n",
    "from speech_commands import freeze\n",
    "from speech_commands import label_wav_dir\n",
    "\n",
    "def train_model(_):\n",
    "    tf.reset_default_graph()\n",
    "    train.main(TRAIN_FLAGS)\n",
    "\n",
    "def run_training(directory):\n",
    "    if not directory:\n",
    "        return \"Please input directory with training folders\"\n",
    "    TRAIN_FLAGS['data_dir'] = directory\n",
    "    #train_model('done')\n",
    "    tf.app.run(main=train_model, argv=['train.py'])\n",
    "\n",
    "def freeze_model(_):\n",
    "    tf.reset_default_graph()\n",
    "    freeze.main(FREEZE_FLAGS)\n",
    "\n",
    "def run_freeze(checkpoint, model_out):\n",
    "    if not checkpoint or not model_out:\n",
    "        return \"Please input the checkpoint to freeze and the name of the output model\"\n",
    "    FREEZE_FLAGS['start_checkpoint'] = checkpoint\n",
    "    FREEZE_FLAGS['output_file'] = model_out\n",
    "    freeze_model('done')\n",
    "    ckpts = glob.glob('/tmp/speech_commands_train/conv.*')\n",
    "    for f in ckpts:\n",
    "        os.remove(f)\n",
    "    os.remove('/tmp/speech_commands_train/checkpoint')\n",
    "    #tf.app.run(main=freeze_model, argv=['freeze.py'])\n",
    "\n",
    "def inference_model(_):\n",
    "    global EXPERIMENT_RESULTS\n",
    "    EXPERIMENT_RESULTS = label_wav_dir.main(INFERENCE_FLAGS)\n",
    "\n",
    "def run_inference(directory, model, labels):\n",
    "    if not directory:\n",
    "        return \"Please input the directory with wav files\"\n",
    "    if not model:\n",
    "        return \"Please input the model for inference\"\n",
    "    if not labels:\n",
    "        return \"Please input the file with labels\"\n",
    "    INFERENCE_FLAGS['wav_dir'] = directory\n",
    "    INFERENCE_FLAGS['graph'] = model\n",
    "    INFERENCE_FLAGS['labels'] = labels\n",
    "    print(INFERENCE_FLAGS)\n",
    "    inference_model('done')\n",
    "    #tf.app.run(main=inference_model, argv=['label_wav_dir.py'])\n",
    "    \n",
    "def test(query_strategy, test_folder, model, labels):\n",
    "    # run inferences on male and female test sets\n",
    "    male_audio = test_folder + '/male'\n",
    "    female_audio = test_folder + '/female'\n",
    "    total_male = 0\n",
    "    total_female = 0\n",
    "    correct_male = 0\n",
    "    incorrect_male = 0\n",
    "    correct_female = 0\n",
    "    incorrect_female = 0\n",
    "    # male test\n",
    "    run_inference(male_audio, model, labels)\n",
    "    for row in EXPERIMENT_RESULTS:\n",
    "        total_male += 1\n",
    "        if 'male' in row and 'female' in row:\n",
    "            if row['male'] > row['female']:\n",
    "                correct_male += 1\n",
    "            else:\n",
    "                incorrect_male += 1\n",
    "        else:\n",
    "            if 'male' in row:\n",
    "                correct_male += 1\n",
    "            elif 'female' in row:\n",
    "                incorrect_male += 1\n",
    "    # female test\n",
    "    run_inference(female_audio, model, labels)\n",
    "    for row in EXPERIMENT_RESULTS:\n",
    "        total_female += 1\n",
    "        if 'male' in row and 'female' in row:\n",
    "            if row['male'] > row['female']:\n",
    "                incorrect_female += 1\n",
    "            else:\n",
    "                correct_female += 1\n",
    "        else:\n",
    "            if 'male' in row:\n",
    "                incorrect_female += 1\n",
    "            elif 'female' in row:\n",
    "                correct_female += 1\n",
    "    total = total_male + total_female\n",
    "    total_correct = correct_male + correct_female\n",
    "    total_incorrect = incorrect_male + incorrect_female\n",
    "    tpr = total_correct / total\n",
    "    fpr = total_incorrect / total\n",
    "    qs_train_size = 0\n",
    "    male_count = len(glob.glob(ROOT_DATA + query_strategy + '/train/male/*.wav'))\n",
    "    female_count = len(glob.glob(ROOT_DATA + query_strategy + '/train/female/*.wav'))\n",
    "    qs_train_size = male_count + female_count\n",
    "    x = qs_train_size\n",
    "    y = tpr\n",
    "    if query_strategy in CLASSIFIER_STATS:\n",
    "        CLASSIFIER_STATS[query_strategy]['x'].append(x)\n",
    "        CLASSIFIER_STATS[query_strategy]['y'].append(y)\n",
    "    else:\n",
    "        CLASSIFIER_STATS[query_strategy] = {'x':[x], 'y':[y]}\n",
    "    return 'Accuracy is ' + str(tpr) + '%'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEXAMPLES TO CALL THE FUNCTIONS\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "EXAMPLES TO CALL THE FUNCTIONS\n",
    "\"\"\"\n",
    "# run training of the model\n",
    "# run_training(ROOT_DATA + 'supervised_learning/train')\n",
    "\n",
    "# freeze the model\n",
    "# run_freeze('/tmp/speech_commands_train/conv.ckpt-2', 'supervised_1.pb')\n",
    "\n",
    "# run inferences\n",
    "# run_inference(ROOT_DATA + 'confidence_sampling/unlabeled', 'confidence_sampling_1.pb', '/tmp/speech_commands_train/conv_labels.txt')\n",
    "\n",
    "# run test\n",
    "# test('supervised_learning', ROOT_DATA + '/test', 'supervised_1.pb', '/tmp/speech_commands_train/conv_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper functions for Active Learning Workshop\n",
    "\"\"\"\n",
    "\n",
    "def prep_query_strategy(name):\n",
    "    qs_folder = ROOT_DATA + name\n",
    "    if not os.path.exists(qs_folder):\n",
    "        os.mkdir(qs_folder)\n",
    "    unlabeled = qs_folder + '/unlabeled'\n",
    "    train = qs_folder + '/train'\n",
    "    male = train + '/male'\n",
    "    female = train + '/female'\n",
    "    if not os.path.exists(unlabeled):\n",
    "        os.mkdir(unlabeled)\n",
    "    if not os.path.exists(train):\n",
    "        os.mkdir(train)\n",
    "    if not os.path.exists(male):\n",
    "        os.mkdir(male)\n",
    "    if not os.path.exists(female):\n",
    "        os.mkdir(female)\n",
    "    files = glob.glob(ROOT_DATA + '/unlabeled/*')\n",
    "    for f in files:\n",
    "        fname = f.split('/')[-1]\n",
    "        new_loc = unlabeled + '/' + fname\n",
    "        if not os.path.exists(new_loc):\n",
    "            shutil.copyfile(f, new_loc)\n",
    "    \n",
    "    \n",
    "def random_seed_data(query_strategy):\n",
    "    qs_folder = ROOT_DATA + query_strategy\n",
    "    if not os.path.exists(qs_folder):\n",
    "        prep_query_strategy(query_strategy)\n",
    "    unlabeled = qs_folder + '/unlabeled'\n",
    "    files = glob.glob(unlabeled + '/*.wav')\n",
    "    seed_data = random.sample(files, 100)\n",
    "    male = 0\n",
    "    female = 0\n",
    "    train = qs_folder + '/train'\n",
    "    for s in seed_data:\n",
    "        fn = s.split('/')[-1]\n",
    "        mf = fn.split('_')[0]\n",
    "\n",
    "        if mf == 'male':\n",
    "            dest = train + '/male/' + fn\n",
    "            male += 1\n",
    "        else:\n",
    "            dest = train + '/female/' + fn\n",
    "            female += 1\n",
    "        shutil.move(s, dest)\n",
    "    print('Male examples: ' + str(male))\n",
    "    print('Female examples: ' + str(female))\n",
    "\n",
    "def label_data(query_strategy, data):\n",
    "    qs_folder = ROOT_DATA + query_strategy\n",
    "    train = qs_folder + '/train'\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "    for f in data:\n",
    "        fn = f.split('/')[-1]\n",
    "        label = fn.split('_')[0]\n",
    "        if label == 'male':\n",
    "            dest = train + '/male/' + fn\n",
    "            male_count += 1\n",
    "        else:\n",
    "            dest = train + '/female/' + fn\n",
    "            female_count += 1\n",
    "        shutil.move(f, dest)\n",
    "    print('Successfully labeled ' + str(male_count) + ' male audio')\n",
    "    print('Successfully labeled ' + str(female_count) + ' female audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0: Supervised Learning\n",
    "In the exercise we will use basic supervised learning to update the classifier. This works by selecting a random set of data, labeling that data, and using that to train each class of the classifier.\n",
    "\n",
    "First, we will test the new classifier that we created. Once we have a baseline accuracy we will use the `supervised_learning()` function to get new batches of data for each class in the form of .zip files which we will use to update each class of the Watson classifier.\n",
    "\n",
    "Use the function below to automatically select random data, get the labels, and create the zip files required to add to each class of the Watson classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male examples: 50\n",
      "Female examples: 50\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell initialized the data for supervised learning strategy\n",
    "\"\"\"\n",
    "prep_query_strategy('supervised_learning')\n",
    "random_seed_data('supervised_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training from step: 1 \n",
      "INFO:tensorflow:Step #1: rate 0.001000, accuracy 40.0%, cross entropy 1.374513\n",
      "INFO:tensorflow:Step #2: rate 0.000100, accuracy 40.0%, cross entropy 2.200936\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0 16  0]\n",
      " [ 0  0 18  0]]\n",
      "INFO:tensorflow:Step 2: Validation accuracy = 47.1% (N=34)\n",
      "INFO:tensorflow:Saving to \"/tmp/speech_commands_train/conv.ckpt-2\"\n",
      "INFO:tensorflow:set_size=46\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0 21  0]\n",
      " [ 0  0 25  0]]\n",
      "INFO:tensorflow:Final test accuracy = 45.7% (N=46)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvajapey/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell trains the first model for supervised learning\n",
    "\"\"\"\n",
    "run_training(ROOT_DATA + 'supervised_learning/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clip_duration_ms': 10000, 'clip_stride_ms': 30, 'feature_bin_count': 40, 'model_architecture': 'conv', 'output_file': 'supervised_1.pb', 'preprocess': 'mfcc', 'quantize': False, 'sample_rate': 48000, 'start_checkpoint': '/tmp/speech_commands_train/conv.ckpt-2', 'wanted_words': 'male,female', 'window_size_ms': 30.0, 'window_stride_ms': 10.0}\n",
      "INFO:tensorflow:Restoring parameters from /tmp/speech_commands_train/conv.ckpt-2\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "Converted 6 variables to const ops.\n",
      "INFO:tensorflow:Saved frozen graph to supervised_1.pb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell creates the first graph for supervised learning\n",
    "\"\"\"\n",
    "run_freeze('/tmp/speech_commands_train/conv.ckpt-2', 'supervised_1.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wav_dir': '/Users/kvajapey/Documents/CrowdFlower/Conferences/Beijing/workshop/data/gender_detection//test/male', 'graph': 'supervised_1.pb', 'labels': '/tmp/speech_commands_train/conv_labels.txt', 'input_name': 'wav_data:0', 'output_name': 'labels_softmax:0', 'how_many_labels': 2}\n",
      "{'wav_dir': '/Users/kvajapey/Documents/CrowdFlower/Conferences/Beijing/workshop/data/gender_detection//test/female', 'graph': 'supervised_1.pb', 'labels': '/tmp/speech_commands_train/conv_labels.txt', 'input_name': 'wav_data:0', 'output_name': 'labels_softmax:0', 'how_many_labels': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy is 0.5128205128205128%'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell tests the accuracy of the first supervised learning model\n",
    "\"\"\"\n",
    "test('supervised_learning', ROOT_DATA + '/test', 'supervised_1.pb', '/tmp/speech_commands_train/conv_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will run a series of supervised learning steps. Here you will run the following code add data to your training data and test the model to check how accuracy is improving. As you complete each round of training, you should run the test code to see how the model accuracy improves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "description: function for supervised learning.\n",
    "\"\"\"\n",
    "def supervised_learning_train():\n",
    "    random_seed_data('supervised_learning')\n",
    "    run_training(ROOT_DATA + 'supervised_learning/train')\n",
    "\n",
    "def supervised_learning_run():\n",
    "    run_freeze('/tmp/speech_commands_train/conv.ckpt-2', 'supervised_1.pb')\n",
    "    test('supervised_learning', ROOT_DATA + '/test', 'supervised_1.pb', '/tmp/speech_commands_train/conv_labels.txt')\n",
    "    plt.plot(CLASSIFIER_STATS['supervised_learning']['x'], CLASSIFIER_STATS['supervised_learning']['y'],'ro')\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male examples: 50\n",
      "Female examples: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvajapey/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training from step: 1 \n",
      "INFO:tensorflow:Step #1: rate 0.001000, accuracy 45.0%, cross entropy 1.671158\n",
      "INFO:tensorflow:Step #2: rate 0.000100, accuracy 55.0%, cross entropy 1.195272\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  3  7]\n",
      " [ 0  0  3 11]]\n",
      "INFO:tensorflow:Step 2: Validation accuracy = 58.3% (N=24)\n",
      "INFO:tensorflow:Saving to \"/tmp/speech_commands_train/conv.ckpt-2\"\n",
      "INFO:tensorflow:set_size=33\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  2 13]\n",
      " [ 0  0  5 13]]\n",
      "INFO:tensorflow:Final test accuracy = 45.5% (N=33)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvajapey/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code to add training data and train a new model\n",
    "\"\"\"\n",
    "supervised_learning_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clip_duration_ms': 10000, 'clip_stride_ms': 30, 'feature_bin_count': 40, 'model_architecture': 'conv', 'output_file': 'supervised_1.pb', 'preprocess': 'mfcc', 'quantize': False, 'sample_rate': 48000, 'start_checkpoint': '/tmp/speech_commands_train/conv.ckpt-2', 'wanted_words': 'male,female', 'window_size_ms': 30.0, 'window_stride_ms': 10.0}\n",
      "INFO:tensorflow:Restoring parameters from /tmp/speech_commands_train/conv.ckpt-2\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "Converted 6 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvajapey/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved frozen graph to supervised_1.pb\n",
      "{'wav_dir': '/Users/kvajapey/Documents/CrowdFlower/Conferences/Beijing/workshop/data/gender_detection//test/male', 'graph': 'supervised_1.pb', 'labels': '/tmp/speech_commands_train/conv_labels.txt', 'input_name': 'wav_data:0', 'output_name': 'labels_softmax:0', 'how_many_labels': 2}\n",
      "{'wav_dir': '/Users/kvajapey/Documents/CrowdFlower/Conferences/Beijing/workshop/data/gender_detection//test/female', 'graph': 'supervised_1.pb', 'labels': '/tmp/speech_commands_train/conv_labels.txt', 'input_name': 'wav_data:0', 'output_name': 'labels_softmax:0', 'how_many_labels': 2}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create the inference grapn and run a new test with plot\n",
    "\"\"\"\n",
    "supervised_learning_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Run iterations of supervised learning and plot the accuracy of the model as more data is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write the code to run additional tests after each round of training\n",
    "# HINT: This is the same code used above to complete the first round of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Confidence Sampling\n",
    "In this exercise you will use confidence-based sampling. The goal is to create a query method that will rapidly increase the accuracy of your model with as little data as possible.\n",
    "\n",
    "The idea of confidence sampling is that you are making inferences on your initial classifier. Based on the confidence of these inferences you want to intelligently select which examples you want to add directly to your model and which samples you want to explicitly label.\n",
    "\n",
    "#### Task: Create a function that uses confidence sampling to select which examples should be manually labeled. Once these have been selected run them through the label function and create batches to be added to the classifier.\n",
    "\n",
    "#### NOTE: Make sure to run a preliminary test to get a baseline accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRun preliminary test of classifier to get baseline accuracy\\nThis cell initialized the data for supervised learning strategy\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run preliminary test of classifier to get baseline accuracy\n",
    "This cell initialized the data for supervised learning strategy\n",
    "\"\"\"\n",
    "prep_query_strategy('confidence_sampling')\n",
    "random_seed_data('confidence_sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: basic_confidence_sampling\n",
    "threshold (float): float between 0 and 1 for threshold to label images\n",
    "\"\"\"\n",
    "\n",
    "def confidence_sampling_train():\n",
    "    random_seed_data('confidence_sampling')\n",
    "    run_training(ROOT_DATA + 'confidence_sampling/train')\n",
    "\n",
    "\"\"\"\n",
    "EXAMPLE FOR CONFIDENCE SAMPLING QUERY STRATEGY\n",
    "def confidence_sampling_create_graph():\n",
    "    EXAMPLE CODE FOR CONFIDENCE SAMPLING\n",
    "    run_freeze('/tmp/speech_commands_train/conv.ckpt-2', 'confidence_sampling_1.pb')\n",
    "\n",
    "def confidence_sampling():\n",
    "    run_inference(ROOT_DATA + 'confidence_sampling/unlabeled', 'confidence_sampling_1.pb', '/tmp/speech_commands_train/conv_labels.txt')\n",
    "    data_to_label = []\n",
    "    for res in EXPERIMENT_RESULTS:\n",
    "        if res['female'] < 0.5 and res['male'] < 0.5:\n",
    "            data_to_label.append(res['filename'])\n",
    "    label_data('confidence_sampling', data_to_label)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_sampling_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_sampling_create_graph()\n",
    "confidence_sampling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Margin Sampling\n",
    "In this exercise we will use margin sampling to train a third classifier. In margin sampling we want to look at the various predictions provided by the classifier and determine what threshold should be set in order to label the least number of images while getting the most performance gains out of the classifier.\n",
    "\n",
    "An example of margin sampling could be to manually label any item where the top two predictions are within 20% confidence of one another.\n",
    "\n",
    "For example:\n",
    "\n",
    "`\n",
    "Audio 1: {'male': 0.77, 'female': 0.73}\n",
    "`\n",
    "\n",
    "Here we can see that \"male\" and \"female\" are very close and we should get an explicit label to make it apparent which one we should use.\n",
    "\n",
    "#### NOTE: Make sure to run a preliminary test to get a baseline accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run preliminary test of classifier to get baseline accuracy\n",
    "This cell initialized the data for supervised learning strategy\n",
    "\"\"\"\n",
    "prep_query_strategy('margin_sampling')\n",
    "random_seed_data('margin_sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nEXAMPLE FOR MARGIN SAMPLING QUERY STRATEGY\\ndef margin_sampling_create_graph():\\n    EXAMPLE CODE FOR CONFIDENCE SAMPLING\\n    run_freeze('/tmp/speech_commands_train/conv.ckpt-2', 'confidence_sampling_1.pb')\\n\\ndef margin_sampling():\\n    run_inference(ROOT_DATA + 'confidence_sampling/unlabeled', 'confidence_sampling_1.pb', '/tmp/speech_commands_train/conv_labels.txt')\\n    data_to_label = []\\n    for res in EXPERIMENT_RESULTS:\\n        # FILL IN QUERY STRATEGY HERE\\n    label_data('margin_sampling', data_to_label)\\n\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def margin_sampling_train():\n",
    "    random_seed_data('margin_sampling')\n",
    "    run_training(ROOT_DATA + 'margin_sampling/train')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "EXAMPLE FOR MARGIN SAMPLING QUERY STRATEGY\n",
    "def margin_sampling_create_graph():\n",
    "    EXAMPLE CODE FOR CONFIDENCE SAMPLING\n",
    "    run_freeze('/tmp/speech_commands_train/conv.ckpt-2', 'confidence_sampling_1.pb')\n",
    "\n",
    "def margin_sampling():\n",
    "    run_inference(ROOT_DATA + 'confidence_sampling/unlabeled', 'confidence_sampling_1.pb', '/tmp/speech_commands_train/conv_labels.txt')\n",
    "    data_to_label = []\n",
    "    for res in EXPERIMENT_RESULTS:\n",
    "        # FILL IN QUERY STRATEGY HERE\n",
    "    label_data('margin_sampling', data_to_label)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write your code here to test your classifier after each round of training\n",
    "HINT: This is similar to the test and plot code bits used in previous exercises\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Query by Committee\n",
    "In this exercise we want to create a query by committee strategy. You have a couple options.\n",
    "\n",
    "1. Use the three classifiers you trained above as your \"committee\" and update all classifiers\n",
    "2. Delete the three classifiers and create three new ones to be used for the query by committee.\n",
    "\n",
    "Three different intializer datasets are provided so feel free to use those to create your initial classifiers.\n",
    "\n",
    "#### NOTE: Make sure to run a preliminary test to get a baseline accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_by_committee():\n",
    "    # TODO: Create a query by committee function.\n",
    "    # Like before the goal should be to create three zip files in this\n",
    "    # function that will be the training data to be added to the classifier\n",
    "    # Also after each round of training we want to run our test to see how\n",
    "    # the accuracy is improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write your code here to test your classifier after each round of training\n",
    "HINT: This is similar to the test and plot code bits used in previous exercises\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Build your own\n",
    "In this exercise you will build your own query function using any of the methods used previous. This is where you should get creative and think about the best query strategy to train a model with the least amount of data.\n",
    "\n",
    "#### NOTE: Make sure to run a preliminary test to get a baseline accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_strategy():\n",
    "    pass\n",
    "    # TODO: Fill in your custom query function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite your code here to test your classifier after each round of training\\nHINT: This is similar to the test and plot code bits used in previous exercises\\n'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write your code here to test your classifier after each round of training\n",
    "HINT: This is similar to the test and plot code bits used in previous exercises\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active_learning",
   "language": "python",
   "name": "active_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
